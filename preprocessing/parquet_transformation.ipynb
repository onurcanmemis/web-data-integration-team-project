{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6a4246c",
   "metadata": {},
   "source": [
    "In this notebook we'll be transforming our xml files into parquet files so that it becomes easier to work on them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff14abce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import kagglehub\n",
    "import xmltodict, pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "ROOT = Path.cwd().parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a462b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_int(x):\n",
    "    try:\n",
    "        return int(float(x))\n",
    "    except (TypeError, ValueError):\n",
    "        return None\n",
    "\n",
    "def to_float(x):\n",
    "    try:\n",
    "        return float(x)\n",
    "    except (TypeError, ValueError):\n",
    "        return None\n",
    "\n",
    "def split_pylist_string(s):\n",
    "    \"\"\"\n",
    "    Turn \"['Action', 'Shooter', 'RPG']\" -> ['Action','Shooter','RPG'].\n",
    "    Also handles duplicates and weird spacing/quotes.\n",
    "    \"\"\"\n",
    "    if not isinstance(s, str):\n",
    "        return []\n",
    "    s = s.strip()\n",
    "    if s.startswith(\"[\") and s.endswith(\"]\"):\n",
    "        s = s[1:-1]\n",
    "    parts = [p.strip().strip(\"'\").strip('\"') for p in s.split(\",\")]\n",
    "    # dedupe while preserving order\n",
    "    seen, out = set(), []\n",
    "    for p in parts:\n",
    "        if p and p not in seen:\n",
    "            seen.add(p)\n",
    "            out.append(p)\n",
    "    return out\n",
    "\n",
    "def normalize_genres(g):\n",
    "    \"\"\"\n",
    "    Works for:\n",
    "      - <genres><genre>['Action','Shooter']</genre></genres>  (your case)\n",
    "      - <genres><genre>Action</genre><genre>Shooter</genre></genres>\n",
    "    \"\"\"\n",
    "    genres_node = g.get(\"genres\")\n",
    "    if not genres_node:\n",
    "        return []\n",
    "    items = genres_node.get(\"genre\", [])\n",
    "    # force_list makes 'genre' a list; if not, wrap\n",
    "    if not isinstance(items, list):\n",
    "        items = [items]\n",
    "\n",
    "    out = []\n",
    "    for it in items:\n",
    "        if isinstance(it, dict):\n",
    "            # rare: {'#text': 'Action'}\n",
    "            it = it.get(\"#text\", \"\")\n",
    "        if isinstance(it, str) and it.strip().startswith(\"[\"):\n",
    "            out.extend(split_pylist_string(it))\n",
    "        elif isinstance(it, str):\n",
    "            val = it.strip()\n",
    "            if val:\n",
    "                out.append(val)\n",
    "    # final dedupe, preserve order\n",
    "    seen, final = set(), []\n",
    "    for v in out:\n",
    "        if v not in seen:\n",
    "            seen.add(v)\n",
    "            final.append(v)\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ea044c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"raw/df_metacritic_updated.xml\") as f:\n",
    "    doc = xmltodict.parse(f.read(), force_list=(\"game\",\"genre\"))\n",
    "\n",
    "rows = []\n",
    "for g in doc[\"video_games\"][\"game\"]:\n",
    "    rows.append({\n",
    "        \"title\":        g.get(\"title\"),\n",
    "        \"platform\":     g.get(\"platform\"),\n",
    "        \"release_year\": to_int(g.get(\"release_year\")),\n",
    "        \"developer\":    g.get(\"developer\"),\n",
    "        \"genres\":       normalize_genres(g),\n",
    "        \"critic_score\": to_int(g.get(\"critic_score\")),\n",
    "        \"user_score\":   to_float(g.get(\"user_score\")),\n",
    "        \"esrb_rating\":  g.get(\"esrb_rating\"),\n",
    "    })\n",
    "\n",
    "df_metacritic_xml = pd.DataFrame(rows)\n",
    "#########################################################################\n",
    "with open(\"raw/df_videogamesales_latest.xml\") as f:\n",
    "    doc = xmltodict.parse(f.read(), force_list=(\"game\",\"genre\"))\n",
    "\n",
    "rows = []\n",
    "for g in doc[\"video_games\"][\"game\"]:\n",
    "    rows.append({\n",
    "        # VGSales columns\n",
    "        \"title\": g.get(\"title\"),\n",
    "        \"platform\": g.get(\"platform\"),\n",
    "        \"release_year\": to_int(g.get(\"release_year\")),\n",
    "        \"publisher\": g.get(\"publisher\"),\n",
    "\n",
    "        # genres (list[str] thanks to force_list=(\"game\",\"genre\"))\n",
    "        \"genres\": g.get(\"genres\", {}).get(\"genre\", []),\n",
    "\n",
    "        # regional/global sales (millions)\n",
    "        \"na_sales_mil\":     to_float(g.get(\"na_sales_mil\")),\n",
    "        \"eu_sales_mil\":     to_float(g.get(\"eu_sales_mil\")),\n",
    "        \"jp_sales_mil\":     to_float(g.get(\"jp_sales_mil\")),\n",
    "        \"other_sales_mil\":  to_float(g.get(\"other_sales_mil\")),\n",
    "        \"global_sales_mil\": to_float(g.get(\"global_sales_mil\")),\n",
    "    })\n",
    "df_videogamesales_xml = pd.DataFrame(rows)\n",
    "#########################################################################\n",
    "with open(\"raw/df_playtime.xml\") as f:\n",
    "    doc = xmltodict.parse(f.read(), force_list=(\"game\",\"genre\"))\n",
    "\n",
    "rows = []\n",
    "for g in doc[\"video_games\"][\"game\"]:\n",
    "    rows.append({\n",
    "        # Common metadata\n",
    "        \"title\": g.get(\"title\"),\n",
    "        \"platform\": g.get(\"platform\"),\n",
    "        \"release_year\": to_int(g.get(\"release_year\")),\n",
    "        \"developer\": g.get(\"developer\"),\n",
    "        \"publisher\": g.get(\"publisher\"),\n",
    "\n",
    "        # Genres as list[str]\n",
    "        \"genres\":       normalize_genres(g),\n",
    "\n",
    "        # Time-to-beat (hours)\n",
    "        \"main_story_hour\":       to_float(g.get(\"main_story_hour\")),\n",
    "        \"main_plus_sides_hour\":  to_float(g.get(\"main_plus_sides_hour\")),\n",
    "        \"completionist_hour\":    to_float(g.get(\"completionist_hour\")),\n",
    "    })\n",
    "\n",
    "df_playtime_xml = pd.DataFrame(rows)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33b7652d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a directory called parquet if it doesn't exist\n",
    "import os\n",
    "if not os.path.exists(ROOT/\"parquet\"):\n",
    "    os.mkdir(ROOT/\"parquet\")\n",
    "df_metacritic_xml.to_parquet(ROOT/\"parquet/df_metacritic.parquet\")\n",
    "df_videogamesales_xml.to_parquet(ROOT/\"parquet/df_videogamesales.parquet\")\n",
    "df_playtime_xml.to_parquet(ROOT/\"parquet/df_playtime.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (Python 3.12.7)",
   "language": "python",
   "name": "teamproj-312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
