{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9137b8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from PyDI.io import load_parquet\n",
    "\n",
    "ROOT = Path.cwd().parent\n",
    "\n",
    "DATA_DIR = ROOT / \"parquet\"\n",
    "OUTPUT_DIR = ROOT / \"output\"\n",
    "MLDS_DIR = ROOT / \"ml-datasets\"\n",
    "BLOCK_EVAL_DIR = OUTPUT_DIR / \"blocking_evaluation\"\n",
    "CORR_DIR = OUTPUT_DIR / \"correspondences\"\n",
    "\n",
    "\n",
    "metacritic = load_parquet(DATA_DIR / \"df_metacritic.parquet\", name=\"metacritic\")\n",
    "playtime = load_parquet(DATA_DIR / \"df_playtime.parquet\", name=\"playtime\")\n",
    "sales= load_parquet(DATA_DIR / \"df_videogamesales.parquet\", name=\"videogamesales\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed4e7559",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_row_id(df, dataset_name, id_col=None):\n",
    "    if id_col is None:\n",
    "        id_col = f\"{dataset_name}_row_id\"\n",
    "    df = df.copy()\n",
    "    df.insert(0, id_col, [f\"{dataset_name}_{i+1}\" for i in range(len(df))])\n",
    "    return df\n",
    "\n",
    "metacritic = add_row_id(metacritic, \"metacritic\")\n",
    "sales = add_row_id(sales, \"sales\")\n",
    "playtime = add_row_id(playtime, \"playtime\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9e51561",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sales_row_id</th>\n",
       "      <th>title</th>\n",
       "      <th>platform</th>\n",
       "      <th>release_year</th>\n",
       "      <th>publisher</th>\n",
       "      <th>genres</th>\n",
       "      <th>na_sales_mil</th>\n",
       "      <th>eu_sales_mil</th>\n",
       "      <th>jp_sales_mil</th>\n",
       "      <th>other_sales_mil</th>\n",
       "      <th>global_sales_mil</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sales_1</td>\n",
       "      <td>Wii Sports</td>\n",
       "      <td>Wii</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>[Sports]</td>\n",
       "      <td>41.49</td>\n",
       "      <td>29.02</td>\n",
       "      <td>3.77</td>\n",
       "      <td>8.46</td>\n",
       "      <td>82.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sales_2</td>\n",
       "      <td>Super Mario Bros.</td>\n",
       "      <td>NES</td>\n",
       "      <td>1985.0</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>[Platform]</td>\n",
       "      <td>29.08</td>\n",
       "      <td>3.58</td>\n",
       "      <td>6.81</td>\n",
       "      <td>0.77</td>\n",
       "      <td>40.24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sales_row_id              title platform  release_year publisher  \\\n",
       "0      sales_1         Wii Sports      Wii        2006.0  Nintendo   \n",
       "1      sales_2  Super Mario Bros.      NES        1985.0  Nintendo   \n",
       "\n",
       "       genres  na_sales_mil  eu_sales_mil  jp_sales_mil  other_sales_mil  \\\n",
       "0    [Sports]         41.49         29.02          3.77             8.46   \n",
       "1  [Platform]         29.08          3.58          6.81             0.77   \n",
       "\n",
       "   global_sales_mil  \n",
       "0             82.74  \n",
       "1             40.24  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metacritic_row_id</th>\n",
       "      <th>title</th>\n",
       "      <th>platform</th>\n",
       "      <th>release_year</th>\n",
       "      <th>developer</th>\n",
       "      <th>genres</th>\n",
       "      <th>critic_score</th>\n",
       "      <th>user_score</th>\n",
       "      <th>esrb_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>metacritic_1</td>\n",
       "      <td>Portal 2</td>\n",
       "      <td>Xbox 360</td>\n",
       "      <td>2011</td>\n",
       "      <td>Valve Software</td>\n",
       "      <td>[Action, Shooter, First-Person, Sci-Fi, Arcade]</td>\n",
       "      <td>95.0</td>\n",
       "      <td>8.8</td>\n",
       "      <td>E10+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>metacritic_2</td>\n",
       "      <td>Metal Gear Solid V: The Phantom Pain</td>\n",
       "      <td>Xbox One</td>\n",
       "      <td>2015</td>\n",
       "      <td>Konami</td>\n",
       "      <td>[Modern, Action Adventure, Open-World]</td>\n",
       "      <td>95.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  metacritic_row_id                                 title  platform  \\\n",
       "0      metacritic_1                              Portal 2  Xbox 360   \n",
       "1      metacritic_2  Metal Gear Solid V: The Phantom Pain  Xbox One   \n",
       "\n",
       "   release_year       developer  \\\n",
       "0          2011  Valve Software   \n",
       "1          2015          Konami   \n",
       "\n",
       "                                            genres  critic_score  user_score  \\\n",
       "0  [Action, Shooter, First-Person, Sci-Fi, Arcade]          95.0         8.8   \n",
       "1           [Modern, Action Adventure, Open-World]          95.0         7.5   \n",
       "\n",
       "  esrb_rating  \n",
       "0        E10+  \n",
       "1           M  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>playtime_row_id</th>\n",
       "      <th>title</th>\n",
       "      <th>platform</th>\n",
       "      <th>release_year</th>\n",
       "      <th>developer</th>\n",
       "      <th>publisher</th>\n",
       "      <th>genres</th>\n",
       "      <th>main_story_hour</th>\n",
       "      <th>main_plus_sides_hour</th>\n",
       "      <th>completionist_hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>playtime_1</td>\n",
       "      <td>688(I) Hunter/Killer</td>\n",
       "      <td>PC</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>Sonalysts</td>\n",
       "      <td>Electronic Arts</td>\n",
       "      <td>[Simulation]</td>\n",
       "      <td>10.62</td>\n",
       "      <td>35.37</td>\n",
       "      <td>15.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>playtime_2</td>\n",
       "      <td>'Splosion Man</td>\n",
       "      <td>Xbox 360</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>Twisted Pixel Games</td>\n",
       "      <td>Microsoft Games Studios</td>\n",
       "      <td>[Action]</td>\n",
       "      <td>7.60</td>\n",
       "      <td>9.23</td>\n",
       "      <td>18.77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  playtime_row_id                 title  platform  release_year  \\\n",
       "0      playtime_1  688(I) Hunter/Killer        PC        1997.0   \n",
       "1      playtime_2         'Splosion Man  Xbox 360        2009.0   \n",
       "\n",
       "             developer                publisher        genres  \\\n",
       "0            Sonalysts          Electronic Arts  [Simulation]   \n",
       "1  Twisted Pixel Games  Microsoft Games Studios      [Action]   \n",
       "\n",
       "   main_story_hour  main_plus_sides_hour  completionist_hour  \n",
       "0            10.62                 35.37               15.83  \n",
       "1             7.60                  9.23               18.77  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(sales.head(2))\n",
    "display(metacritic.head(2))\n",
    "display(playtime.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "34e1efb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_cols = [\"title\", \"platform\", \"release_year\"]\n",
    "\n",
    "def build_positive_pairs(left_df, right_df, left_tag, right_tag):\n",
    "    \"\"\"\n",
    "    Create positive pairs where title/platform/release_year match exactly.\n",
    "    `left_tag`/`right_tag` control the suffixes (use 'p', 'm', 's', etc.).\n",
    "    \"\"\"\n",
    "    left = (\n",
    "        left_df[[f\"{left_tag}_row_id\"] + key_cols]\n",
    "        .dropna(subset=key_cols)\n",
    "        .rename(columns={\n",
    "            \"title\": f\"title_{left_tag}\",\n",
    "            \"platform\": f\"platform_{left_tag}\",\n",
    "            \"release_year\": f\"release_year_{left_tag}\",\n",
    "        })\n",
    "    )\n",
    "\n",
    "    right = (\n",
    "        right_df[[f\"{right_tag}_row_id\"] + key_cols]\n",
    "        .dropna(subset=key_cols)\n",
    "        .rename(columns={\n",
    "            \"title\": f\"title_{right_tag}\",\n",
    "            \"platform\": f\"platform_{right_tag}\",\n",
    "            \"release_year\": f\"release_year_{right_tag}\",\n",
    "        })\n",
    "    )\n",
    "\n",
    "    pairs = left.merge(\n",
    "        right,\n",
    "        left_on=[f\"title_{left_tag}\", f\"platform_{left_tag}\", f\"release_year_{left_tag}\"],\n",
    "        right_on=[f\"title_{right_tag}\", f\"platform_{right_tag}\", f\"release_year_{right_tag}\"],\n",
    "        how=\"inner\"\n",
    "    )\n",
    "\n",
    "    ordered_cols = [\n",
    "        f\"{left_tag}_row_id\",\n",
    "        f\"{right_tag}_row_id\",\n",
    "        f\"title_{left_tag}\",\n",
    "        f\"title_{right_tag}\",\n",
    "        f\"platform_{left_tag}\",\n",
    "        f\"platform_{right_tag}\",\n",
    "        f\"release_year_{left_tag}\",\n",
    "        f\"release_year_{right_tag}\",\n",
    "        \"label\",\n",
    "    ]\n",
    "    return pairs.assign(label=1)[ordered_cols]\n",
    "\n",
    "def build_negative_pairs_strict(left_df, right_df, left_tag, right_tag,\n",
    "                                size=None, random_state=0):\n",
    "    \"\"\"\n",
    "    Create *strong* negative pairs:\n",
    "    - same platform\n",
    "    - same release_year\n",
    "    - different title  -> clearly not the same entity\n",
    "    We also make sure we don't accidentally include any positive pair.\n",
    "    \"\"\"\n",
    "    left = (\n",
    "        left_df[[f\"{left_tag}_row_id\"] + key_cols]\n",
    "        .dropna(subset=key_cols)\n",
    "        .rename(columns={\n",
    "            \"title\": f\"title_{left_tag}\",\n",
    "            \"platform\": f\"platform_{left_tag}\",\n",
    "            \"release_year\": f\"release_year_{left_tag}\",\n",
    "        })\n",
    "    )\n",
    "\n",
    "    right = (\n",
    "        right_df[[f\"{right_tag}_row_id\"] + key_cols]\n",
    "        .dropna(subset=key_cols)\n",
    "        .rename(columns={\n",
    "            \"title\": f\"title_{right_tag}\",\n",
    "            \"platform\": f\"platform_{right_tag}\",\n",
    "            \"release_year\": f\"release_year_{right_tag}\",\n",
    "        })\n",
    "    )\n",
    "\n",
    "\n",
    "    candidates = left.merge(\n",
    "        right,\n",
    "        left_on=[f\"platform_{left_tag}\", f\"release_year_{left_tag}\"],\n",
    "        right_on=[f\"platform_{right_tag}\", f\"release_year_{right_tag}\"],\n",
    "        how=\"inner\",\n",
    "    )\n",
    "\n",
    "    \n",
    "    candidates = candidates[\n",
    "        candidates[f\"title_{left_tag}\"] != candidates[f\"title_{right_tag}\"]\n",
    "    ].copy()\n",
    "\n",
    "    # Drop duplicates\n",
    "    candidates = candidates.drop_duplicates(\n",
    "        subset=[f\"{left_tag}_row_id\", f\"{right_tag}_row_id\"]\n",
    "    ).assign(label=0)\n",
    "\n",
    "    # Sampling part\n",
    "    if size is None or size > len(candidates):\n",
    "        size = len(candidates)\n",
    "\n",
    "    negatives = candidates.sample(size, random_state=random_state).reset_index(drop=True)\n",
    "\n",
    "    ordered_cols = [\n",
    "        f\"{left_tag}_row_id\",\n",
    "        f\"{right_tag}_row_id\",\n",
    "        f\"title_{left_tag}\",\n",
    "        f\"title_{right_tag}\",\n",
    "        f\"platform_{left_tag}\",\n",
    "        f\"platform_{right_tag}\",\n",
    "        f\"release_year_{left_tag}\",\n",
    "        f\"release_year_{right_tag}\",\n",
    "        \"label\"\n",
    "    ]\n",
    "    return negatives.assign(label=0)[ordered_cols]\n",
    "\n",
    "pm_positive = build_positive_pairs(playtime, metacritic, \"playtime\", \"metacritic\")\n",
    "ps_positive = build_positive_pairs(playtime, sales, \"playtime\", \"sales\")\n",
    "\n",
    "pm_negative = build_negative_pairs_strict(playtime, metacritic, \"playtime\", \"metacritic\",size=1000)\n",
    "ps_negative = build_negative_pairs_strict(playtime, sales, \"playtime\", \"sales\",size=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "59b6d541",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rapidfuzz import fuzz\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def sim_title(a: str, b: str) -> float:\n",
    "    return fuzz.token_set_ratio(a, b) / 100.0\n",
    "\n",
    "def sim_publisher(a: str, b: str) -> float:\n",
    "    return fuzz.token_set_ratio(a, b) / 100.0\n",
    "\n",
    "def sim_developer(a: str, b: str) -> float:\n",
    "    return fuzz.token_set_ratio(a, b) / 100.0\n",
    "def sim_platform(a: str, b: str) -> float:\n",
    "    return 1.0 if a == b else 0.0\n",
    "\n",
    "def sim_year(y1: float, y2: float) -> float:\n",
    "    diff = abs(y1 - y2)\n",
    "    if diff == 0:\n",
    "        return 1.0\n",
    "    if diff == 1:\n",
    "        return 0.8\n",
    "    if diff == 2:\n",
    "        return 0.6\n",
    "    return 0.0\n",
    "\n",
    "def overall_sim_ps(row):\n",
    "    t   = sim_title(row[\"title_p\"],      row[\"title_s\"])\n",
    "    pl  = sim_platform(row[\"platform_p\"], row[\"platform_s\"])\n",
    "    y   = sim_year(row[\"release_year_p\"], row[\"release_year_s\"])\n",
    "    pub = sim_publisher(row[\"publisher_p\"], row[\"publisher_s\"])\n",
    "    return 0.45 * t + 0.25 * pl + 0.15 * y + 0.15 * pub\n",
    "\n",
    "def overall_sim_pm(row):\n",
    "    \"\"\"\n",
    "    Overall similarity for playtime–metacritic pair:\n",
    "    uses title, platform, release_year, and developer.\n",
    "    \"\"\"\n",
    "    t   = sim_title(row[\"title_p\"],       row[\"title_m\"])\n",
    "    pl  = sim_platform(row[\"platform_p\"], row[\"platform_m\"])\n",
    "    y   = sim_year(row[\"release_year_p\"], row[\"release_year_m\"])\n",
    "    dev = sim_developer(row[\"developer_p\"], row[\"developer_m\"])\n",
    "\n",
    "    return 0.45 * t + 0.25 * pl + 0.15 * y + 0.15 * dev\n",
    "\n",
    "# ---- corner case builder for playtime–sales ----\n",
    "def build_ps_corner_cases(playtime_df, sales_df, threshold=0.85):\n",
    "    \"\"\"\n",
    "    1. Block on platform + release_year to create pair_candidates.\n",
    "    2. Compute overall similarity for each candidate.\n",
    "    3. Keep only rows with similarity >= threshold.\n",
    "    4. Add empty 'label' column for later manual annotation.\n",
    "    \"\"\"\n",
    "\n",
    "    # select + rename columns with p_ / s_ prefixes\n",
    "    p = (\n",
    "        playtime_df[\n",
    "            [\"playtime_row_id\", \"title\", \"platform\", \"release_year\", \"publisher\"]\n",
    "        ]\n",
    "        .dropna(subset=[\"title\", \"platform\", \"release_year\", \"publisher\"])\n",
    "        .rename(columns={\n",
    "            \"playtime_row_id\": \"p_row_id\",\n",
    "            \"title\": \"title_p\",\n",
    "            \"platform\": \"platform_p\",\n",
    "            \"release_year\": \"release_year_p\",\n",
    "            \"publisher\": \"publisher_p\",\n",
    "        })\n",
    "    )\n",
    "\n",
    "    s = (\n",
    "        sales_df[\n",
    "            [\"sales_row_id\", \"title\", \"platform\", \"release_year\", \"publisher\"]\n",
    "        ]\n",
    "        .dropna(subset=[\"title\", \"platform\", \"release_year\", \"publisher\"])\n",
    "        .rename(columns={\n",
    "            \"sales_row_id\": \"s_row_id\",\n",
    "            \"title\": \"title_s\",\n",
    "            \"platform\": \"platform_s\",\n",
    "            \"release_year\": \"release_year_s\",\n",
    "            \"publisher\": \"publisher_s\",\n",
    "        })\n",
    "    )\n",
    "\n",
    "    # 1) BLOCKING: only pair rows with same platform + release_year\n",
    "    pair_candidates = p.merge(\n",
    "        s,\n",
    "        left_on=[\"platform_p\", \"release_year_p\"],\n",
    "        right_on=[\"platform_s\", \"release_year_s\"],\n",
    "        how=\"inner\",\n",
    "    )\n",
    "\n",
    "    # 2) SIMILARITY\n",
    "    pair_candidates[\"similarity\"] = pair_candidates.apply(overall_sim_ps, axis=1)\n",
    "\n",
    "    # 3) FILTER by threshold\n",
    "    corner_df = pair_candidates[\n",
    "    (pair_candidates[\"similarity\"] < 1.0) &\n",
    "    (pair_candidates[\"similarity\"] >= threshold)\n",
    "].copy()\n",
    "\n",
    "    # 4) LABEL column (empty / NaN)\n",
    "    corner_df[\"label\"] = pd.NA\n",
    "\n",
    "    # optional: choose column order\n",
    "    ordered_cols = [\n",
    "        \"p_row_id\", \"s_row_id\",\n",
    "        \"title_p\", \"title_s\",\n",
    "        \"platform_p\", \"platform_s\",\n",
    "        \"release_year_p\", \"release_year_s\",\n",
    "        \"publisher_p\", \"publisher_s\",\n",
    "        \"similarity\", \"label\",\n",
    "    ]\n",
    "    return corner_df[ordered_cols]\n",
    "\n",
    "\n",
    "def build_pm_corner_cases(playtime_df, metacritic_df, threshold=0.85):\n",
    "    \"\"\"\n",
    "    1. Block on platform + release_year to create pair_candidates.\n",
    "    2. Compute overall similarity for each candidate.\n",
    "    3. Keep only rows with threshold <= similarity < 1.0.\n",
    "    4. Add empty 'label' column for later manual annotation.\n",
    "    \"\"\"\n",
    "\n",
    "    # select + rename columns with p_ / m_ prefixes\n",
    "    p = (\n",
    "        playtime_df[\n",
    "            [\"playtime_row_id\", \"title\", \"platform\", \"release_year\", \"developer\"]\n",
    "        ]\n",
    "        .dropna(subset=[\"title\", \"platform\", \"release_year\", \"developer\"])\n",
    "        .rename(columns={\n",
    "            \"playtime_row_id\": \"p_row_id\",\n",
    "            \"title\": \"title_p\",\n",
    "            \"platform\": \"platform_p\",\n",
    "            \"release_year\": \"release_year_p\",\n",
    "            \"developer\": \"developer_p\",\n",
    "        })\n",
    "    )\n",
    "\n",
    "    m = (\n",
    "        metacritic_df[\n",
    "            [\"metacritic_row_id\", \"title\", \"platform\", \"release_year\", \"developer\"]\n",
    "        ]\n",
    "        .dropna(subset=[\"title\", \"platform\", \"release_year\", \"developer\"])\n",
    "        .rename(columns={\n",
    "            \"metacritic_row_id\": \"m_row_id\",\n",
    "            \"title\": \"title_m\",\n",
    "            \"platform\": \"platform_m\",\n",
    "            \"release_year\": \"release_year_m\",\n",
    "            \"developer\": \"developer_m\",\n",
    "        })\n",
    "    )\n",
    "\n",
    "    # 1) BLOCKING: same platform + release_year\n",
    "    pair_candidates = p.merge(\n",
    "        m,\n",
    "        left_on=[\"platform_p\", \"release_year_p\"],\n",
    "        right_on=[\"platform_m\", \"release_year_m\"],\n",
    "        how=\"inner\",\n",
    "    )\n",
    "\n",
    "    # 2) SIMILARITY\n",
    "    pair_candidates[\"similarity\"] = pair_candidates.apply(overall_sim_pm, axis=1)\n",
    "\n",
    "    # 3) FILTER: threshold <= similarity < 1.0\n",
    "    corner_df = pair_candidates[\n",
    "        (pair_candidates[\"similarity\"] >= threshold) &\n",
    "        (pair_candidates[\"similarity\"] < 1.0)\n",
    "    ].copy()\n",
    "\n",
    "    # 4) LABEL column (empty / NaN)\n",
    "    corner_df[\"label\"] = pd.NA\n",
    "\n",
    "    # optional: column order\n",
    "    ordered_cols = [\n",
    "        \"p_row_id\", \"m_row_id\",\n",
    "        \"title_p\", \"title_m\",\n",
    "        \"platform_p\", \"platform_m\",\n",
    "        \"release_year_p\", \"release_year_m\",\n",
    "        \"developer_p\", \"developer_m\",\n",
    "        \"similarity\", \"label\",\n",
    "    ]\n",
    "    return corner_df[ordered_cols]\n",
    "\n",
    "ps_corner = build_ps_corner_cases(playtime, sales, threshold=0.85)\n",
    "pm_corner = build_pm_corner_cases(playtime,metacritic,threshold=0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c305202",
   "metadata": {},
   "outputs": [],
   "source": [
    "pm_corner_a=pd.read_csv(\"labeled_corner_cases/pm_corner_labeled_a.csv\")\n",
    "pm_corner_b=pd.read_csv(\"labeled_corner_cases/pm_corner_labeled_b.csv\")\n",
    "pm_corner_b=pm_corner_b.iloc[:150,:12]\n",
    "pm_corner = pd.concat(\n",
    "    [pm_corner_a.reset_index(drop=True), pm_corner_b.reset_index(drop=True)],ignore_index=True,\n",
    ")\n",
    "ps_corner=pd.read_csv(\"labeled_corner_cases/ps_corner_labeled.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "81b34a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts of labels in Playtime-Metacritic Pair Corner Cases:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "label\n",
       "1.0    275\n",
       "0.0     25\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts of labels in Playtime-Sales Pair Corner Cases:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    278\n",
       "0     22\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Counts of labels in Playtime-Metacritic Pair Corner Cases:\")\n",
    "display(pm_corner.label.value_counts())\n",
    "\n",
    "print(\"Counts of labels in Playtime-Sales Pair Corner Cases:\")\n",
    "display(ps_corner.label.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc850d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compose_20_30_50(pos,neg,corners,\n",
    "    total_n: int,\n",
    "    *,\n",
    "    seed: int = 42,\n",
    "):\n",
    "    \"\"\"\n",
    "    Build a labeled set with the classic 20/30/50 distribution:\n",
    "      - 20% positives (exact ISBN matches)\n",
    "      - 30% corners (text-similarity band; unlabeled -> to be labeled manually)\n",
    "      - 50% negatives (random pairs avoiding equal ISBNs)\n",
    "    Returns: (pos_df, corners_df, neg_df)\n",
    "      pos_df: id_left, id_right, label=1\n",
    "      corners_df: id_left, id_right, title_left, author_left, title_right, author_right, sim, why, label=NA\n",
    "      neg_df: id_left, id_right, label=0\n",
    "    \"\"\"\n",
    "    n_pos = int(round(total_n * 0.20))\n",
    "    n_cor = int(round(total_n * 0.30))\n",
    "    n_neg = total_n - n_pos - n_cor\n",
    "\n",
    "    # 1) full pool of positives, then sample\n",
    "    pos_sample = pos.sample(n=min(n_pos, len(pos)), random_state=seed) if len(pos) else pos\n",
    "\n",
    "    # 2) full set of corners (banded), then sample\n",
    "    corners_sample = corners.sample(n=min(n_cor, len(corners)), random_state=seed) if len(corners) else corners\n",
    "\n",
    "    # 3) sample negatives directly\n",
    "    neg_sample = neg.sample(n=min(n_neg, len(neg)), random_state=seed) if len(neg) else neg\n",
    "\n",
    "\n",
    "    return pos_sample.reset_index(drop=True), corners_sample.reset_index(drop=True), neg_sample.reset_index(drop=True)\n",
    "\n",
    "pos_PS,corners_PS,neg_PS=compose_20_30_50(ps_positive,ps_negative,ps_corner,total_n=1000)\n",
    "pos_PM,corners_PM,neg_PM=compose_20_30_50(pm_positive,pm_negative,pm_corner,total_n=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2fe5aedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_ps = {\"playtime_row_id\": \"id_left\", \"sales_row_id\": \"id_right\"}\n",
    "pos_PS, neg_PS = [df.rename(columns=rename_ps) for df in (pos_PS, neg_PS)]\n",
    "rename_pm = {\"playtime_row_id\": \"id_left\", \"metacritic_row_id\": \"id_right\"}\n",
    "pos_PM, neg_PM = [df.rename(columns=rename_pm) for df in (pos_PM, neg_PM)]\n",
    "\n",
    "corners_PS.rename(columns={\"p_row_id\": \"id_left\", \"s_row_id\": \"id_right\"}, inplace=True)\n",
    "corners_PM.rename(columns={\"p_row_id\": \"id_left\", \"m_row_id\": \"id_right\"}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8ae25778",
   "metadata": {},
   "outputs": [],
   "source": [
    "def finalize_and_split(pos_df, corners_labeled_df, neg_df, *, test_frac=0.2, seed=42):\n",
    "    \"\"\"\n",
    "    Merge positives + labeled corners + negatives, then stratified split (train/test only).\n",
    "    Returns:\n",
    "        train_df, test_df  (each with id_left, id_right, label)\n",
    "    \"\"\"\n",
    "    # Merge all labeled pairs\n",
    "    all_labeled = pd.concat(\n",
    "        [\n",
    "            pos_df[[\"id_left\", \"id_right\", \"label\"]],\n",
    "            corners_labeled_df[[\"id_left\", \"id_right\", \"label\"]],\n",
    "            neg_df[[\"id_left\", \"id_right\", \"label\"]],\n",
    "        ],\n",
    "        ignore_index=True\n",
    "    ).dropna(subset=[\"label\"]).drop_duplicates()\n",
    "\n",
    "    # Ensure binary integer labels\n",
    "    all_labeled[\"label\"] = all_labeled[\"label\"].astype(int)\n",
    "\n",
    "    # Shuffle once for randomness\n",
    "    L = all_labeled.sample(frac=1.0, random_state=seed).reset_index(drop=True)\n",
    "\n",
    "    # Stratified split (preserve 0/1 balance)\n",
    "    parts = {\"train\": [], \"test\": []}\n",
    "    for y in (0, 1):\n",
    "        grp = L[L[\"label\"] == y]\n",
    "        n = len(grp)\n",
    "        n_test = int(round(n * test_frac))\n",
    "        test_part = grp.iloc[:n_test]\n",
    "        train_part = grp.iloc[n_test:]\n",
    "        parts[\"train\"].append(train_part)\n",
    "        parts[\"test\"].append(test_part)\n",
    "\n",
    "    train = pd.concat(parts[\"train\"], ignore_index=True)\n",
    "    test  = pd.concat(parts[\"test\"],  ignore_index=True)\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e173fce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_PS, test_PS = finalize_and_split(pos_PS, corners_PS, neg_PS)\n",
    "train_PM, test_PM = finalize_and_split(pos_PM, corners_PM, neg_PM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5328c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|          |   0 |   1 |\n",
      "|:---------|----:|----:|\n",
      "| train_PS | 418 | 378 |\n",
      "| test_PS  | 104 |  95 |\n",
      "| train_PM | 420 | 375 |\n",
      "| test_PM  | 105 |  94 |\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "counts = pd.concat(\n",
    "    {\n",
    "        \"train_PS\": train_PS.label.value_counts(),\n",
    "        \"test_PS\":  test_PS.label.value_counts(),\n",
    "        \"train_PM\": train_PM.label.value_counts(),\n",
    "        \"test_PM\":  test_PM.label.value_counts(),\n",
    "    },\n",
    "    axis=1,\n",
    ").fillna(0).astype(int).T  # rows = splits, cols = labels\n",
    "\n",
    "print(counts.to_markdown())   # or display(counts) in a notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f5f61e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "out_dir = Path(ROOT) / MLDS_DIR\n",
    "try:\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "except OSError as e:\n",
    "    raise RuntimeError(f\"Cannot create output dir {out_dir}\") from e\n",
    "\n",
    "for name, df in {\n",
    "    \"train_PS.parquet\": train_PS,\n",
    "    \"train_PM.parquet\": train_PM,\n",
    "    \"test_PS.parquet\":  test_PS,\n",
    "    \"test_PM.parquet\":  test_PM,\n",
    "}.items():\n",
    "    df.to_parquet(out_dir / name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffb33b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
